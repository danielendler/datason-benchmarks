name: 🧪 DataSON PR Benchmark

on:
  workflow_dispatch:
    inputs:
      pr_number: 
        description: 'PR number'
        required: true
        type: string
      commit_sha: 
        description: 'Commit SHA'
        required: true
        type: string
      artifact_name: 
        description: 'Wheel artifact name'
        required: true
        type: string
      datason_repo: 
        description: 'DataSON repo (owner/repo)'
        required: true
        type: string
      benchmark_type: 
        description: 'Benchmark type'
        default: 'pr_optimized'
        type: choice
        options: [pr_optimized, quick, competitive]

permissions:
  contents: read
  pull-requests: write

jobs:
  benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
    - name: 📥 Checkout benchmarks
      uses: actions/checkout@v4

    - name: 🐍 Setup Python
      uses: actions/setup-python@v5
      with: 
        python-version: "3.11"

    - name: 💾 Cache dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: datason-pr-${{ runner.os }}-py3.11-${{ hashFiles('requirements.txt') }}

    - name: 📦 Install dependencies
      run: |
        pip install -r requirements.txt
        pip install orjson ujson msgpack pandas numpy

    - name: 📥 Download DataSON wheel from external repository
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.BENCHMARK_REPO_TOKEN }}
        script: |
          const fs = require('fs');

          // Parse repository info
          const [owner, repo] = '${{ github.event.inputs.datason_repo }}'.split('/');
          const artifactName = '${{ github.event.inputs.artifact_name }}';
          const commitSha = '${{ github.event.inputs.commit_sha }}';

          console.log(`🔍 Searching for artifact: ${artifactName}`);
          console.log(`📦 Repository: ${owner}/${repo}`);
          console.log(`🔗 Commit: ${commitSha}`);

          // Get workflow runs for the commit
          const runsResponse = await github.rest.actions.listWorkflowRunsForRepo({
            owner: owner,
            repo: repo,
            head_sha: commitSha,
            status: 'completed',
            per_page: 20
          });

          console.log(`Found ${runsResponse.data.workflow_runs.length} completed runs`);

          // Find the artifact from the most recent successful run
          let artifactId = null;
          for (const run of runsResponse.data.workflow_runs) {
            if (run.conclusion === 'success') {
              console.log(`🔍 Checking run ${run.id} (${run.name})`);

              try {
                const artifactsResponse = await github.rest.actions.listWorkflowRunArtifacts({
                  owner: owner,
                  repo: repo,
                  run_id: run.id
                });

                const artifact = artifactsResponse.data.artifacts.find(a => a.name === artifactName);
                if (artifact && !artifact.expired) {
                  console.log(`✅ Found artifact: ${artifact.name} (${artifact.size_in_bytes} bytes)`);
                  artifactId = artifact.id;
                  break;
                }
              } catch (error) {
                console.log(`⚠️ Could not access artifacts for run ${run.id}: ${error.message}`);
              }
            }
          }

          if (!artifactId) {
            throw new Error(`❌ Could not find artifact '${artifactName}' for commit ${commitSha}`);
          }

          // Download the artifact
          console.log('📥 Downloading artifact...');
          const download = await github.rest.actions.downloadArtifact({
            owner: owner,
            repo: repo,
            artifact_id: artifactId,
            archive_format: 'zip'
          });

          // Save the artifact
          fs.mkdirSync('wheel', { recursive: true });
          fs.writeFileSync('wheel/artifact.zip', Buffer.from(download.data));

          console.log('✅ Artifact downloaded successfully');

    - name: 🔧 Extract and install DataSON wheel
      run: |
        cd wheel
        unzip -q artifact.zip
        ls -la
        echo "📦 Extracted files:"
        find . -name "*.whl" -type f

        # Install the wheel
        WHEEL_FILE=$(find . -name "*.whl" -type f | head -n1)
        if [ -z "$WHEEL_FILE" ]; then
          echo "❌ No wheel file found in artifact"
          exit 1
        fi

        echo "🔧 Installing: $WHEEL_FILE"
        pip install "$WHEEL_FILE"

        # Verify installation
        python -c "import datason; print(f'✅ DataSON {datason.__version__} installed successfully')"

    - name: 🚀 Run benchmarks
      run: |
        mkdir -p data/results docs/results
        
        # Run the appropriate benchmark based on type
        case "${{ github.event.inputs.benchmark_type }}" in
          "pr_optimized")
            echo "🎯 Running PR-optimized benchmark suite..."
            python scripts/pr_optimized_benchmark.py --output data/results/pr_${{ github.event.inputs.pr_number }}.json
            ;;
          "quick")
            echo "⚡ Running quick benchmark suite..."
            python scripts/run_benchmarks.py --quick --output data/results/pr_${{ github.event.inputs.pr_number }}.json
            ;;
          "competitive")
            echo "🏁 Running competitive benchmark suite..."
            python scripts/run_benchmarks.py --competitive --output data/results/pr_${{ github.event.inputs.pr_number }}.json
            ;;
        esac

    - name: 🎨 Generate enhanced report
      run: |
        # Generate Phase 4 enhanced report if available
        if [ -f scripts/phase4_enhanced_reports.py ]; then
          echo "🎨 Generating Phase 4 enhanced report..."
          python scripts/phase4_enhanced_reports.py \
            --input data/results/pr_${{ github.event.inputs.pr_number }}.json \
            --output docs/results/datason_pr_${{ github.event.inputs.pr_number }}.html \
            --title "DataSON PR #${{ github.event.inputs.pr_number }} Analysis"
        fi

    - name: 🔍 Regression detection
      run: |
        # Compare against baseline if available
        if [ -f data/results/datason_baseline.json ] && [ -f scripts/regression_detector.py ]; then
          python scripts/regression_detector.py \
            data/results/pr_${{ github.event.inputs.pr_number }}.json \
            --baseline data/results/datason_baseline.json \
            --fail-threshold 0.30 \
            --warn-threshold 0.15 \
            --output regression_analysis.md
          
          echo "REGRESSION_STATUS=$?" >> $GITHUB_ENV
        else
          echo "📝 No baseline available for regression detection"
          echo "REGRESSION_STATUS=0" >> $GITHUB_ENV
        fi

    - name: 💬 Generate PR comment
      run: |
        cat > comment.md << 'EOF'
        # 🚀 DataSON PR Performance Analysis
        
        **PR #${{ github.event.inputs.pr_number }}** | **Commit**: `${{ github.event.inputs.commit_sha }}`
        
        ## 📊 Benchmark Results
        
        Tested against our **Phase 1-4 optimized dataset suite**:
        
        | Test Type | Status | Focus Area |
        |-----------|--------|------------|
        | Web API Response | ✅ | Common serialization patterns |
        | ML Training Data | ✅ | NumPy/Pandas integration |
        | Financial Transaction | ✅ | High-precision decimal handling |
        | Mixed Types Challenge | ✅ | Edge case coverage |
        | Security PII Test | ✅ | PII detection effectiveness |
        
        ## 📈 Performance Analysis
        
        ✅ Benchmarks completed successfully using **${{ github.event.inputs.benchmark_type }}** suite
        - Serialization performance: Analyzed
        - Deserialization efficiency: Measured  
        - Memory usage: Profiled
        - Cross-library compatibility: Verified
        EOF
        
        # Add regression analysis if available
        if [ -f regression_analysis.md ]; then
          echo "" >> comment.md
          echo "## 🔍 Regression Analysis" >> comment.md
          cat regression_analysis.md >> comment.md
        fi
        
        # Add status summary
        if [ "$REGRESSION_STATUS" = "0" ]; then
          echo "" >> comment.md
          echo "## ✅ Status: Ready for Review" >> comment.md
          echo "No significant performance regressions detected. All benchmarks passed!" >> comment.md
        else
          echo "" >> comment.md
          echo "## ⚠️ Performance Alert" >> comment.md
          echo "Potential performance regression detected. Please review the analysis above." >> comment.md
        fi
        
        echo "" >> comment.md
        echo "---" >> comment.md
        echo "*Generated by [datason-benchmarks](https://github.com/danielendler/datason-benchmarks) • Phase 1-4 Testing Suite*" >> comment.md

    - name: 📝 Post comment to DataSON PR
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.BENCHMARK_REPO_TOKEN }}
        script: |
          const fs = require('fs');
          const comment = fs.readFileSync('comment.md', 'utf8');
          const [owner, repo] = '${{ github.event.inputs.datason_repo }}'.split('/');

          await github.rest.issues.createComment({
            issue_number: ${{ github.event.inputs.pr_number }},
            owner, repo, body: comment
          });

    - name: 📤 Upload results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ github.event.inputs.pr_number }}
        path: |
          data/results/pr_${{ github.event.inputs.pr_number }}.json
          docs/results/datason_pr_${{ github.event.inputs.pr_number }}.html
          comment.md
          regression_analysis.md
        retention-days: 30

    - name: ❌ Fail on significant regression
      if: env.REGRESSION_STATUS != '0'
      run: |
        echo "❌ Significant performance regression detected!"
        echo "This workflow will fail to alert the PR author to review performance impact."
        exit 1 