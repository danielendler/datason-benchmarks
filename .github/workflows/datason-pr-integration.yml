name: ğŸ§ª DataSON PR Benchmark

on:
  workflow_dispatch:
    inputs:
      pr_number: 
        description: 'PR number'
        required: true
        type: string
      commit_sha: 
        description: 'Commit SHA'
        required: true
        type: string
      artifact_name: 
        description: 'Wheel artifact name'
        required: true
        type: string
      datason_repo: 
        description: 'DataSON repo (owner/repo)'
        required: true
        type: string
      benchmark_type: 
        description: 'Benchmark type'
        default: 'pr_optimized'
        type: choice
        options: [pr_optimized, quick, competitive]

permissions:
  contents: read
  pull-requests: write

jobs:
  benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
    - name: ğŸ“¥ Checkout benchmarks
      uses: actions/checkout@v4

    - name: ğŸ Setup Python
      uses: actions/setup-python@v5
      with: 
        python-version: "3.11"

    - name: ğŸ’¾ Cache dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: datason-pr-${{ runner.os }}-py3.11-${{ hashFiles('requirements.txt') }}

    - name: ğŸ“¦ Install dependencies
      run: |
        pip install -r requirements.txt
        pip install orjson ujson msgpack pandas numpy

    - name: ğŸ“¥ Download DataSON wheel from external repository
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.BENCHMARK_REPO_TOKEN }}
        script: |
          const fs = require('fs');

          // Parse repository info
          const [owner, repo] = '${{ github.event.inputs.datason_repo }}'.split('/');
          const artifactName = '${{ github.event.inputs.artifact_name }}';
          const commitSha = '${{ github.event.inputs.commit_sha }}';

          console.log(`ğŸ” Searching for artifact: ${artifactName}`);
          console.log(`ğŸ“¦ Repository: ${owner}/${repo}`);
          console.log(`ğŸ”— Commit: ${commitSha}`);

          // Get workflow runs for the commit
          const runsResponse = await github.rest.actions.listWorkflowRunsForRepo({
            owner: owner,
            repo: repo,
            head_sha: commitSha,
            status: 'completed',
            per_page: 20
          });

          console.log(`Found ${runsResponse.data.workflow_runs.length} completed runs`);

          // Find the artifact from the most recent successful run
          let artifactId = null;
          for (const run of runsResponse.data.workflow_runs) {
            if (run.conclusion === 'success') {
              console.log(`ğŸ” Checking run ${run.id} (${run.name})`);

              try {
                const artifactsResponse = await github.rest.actions.listWorkflowRunArtifacts({
                  owner: owner,
                  repo: repo,
                  run_id: run.id
                });

                const artifact = artifactsResponse.data.artifacts.find(a => a.name === artifactName);
                if (artifact && !artifact.expired) {
                  console.log(`âœ… Found artifact: ${artifact.name} (${artifact.size_in_bytes} bytes)`);
                  artifactId = artifact.id;
                  break;
                }
              } catch (error) {
                console.log(`âš ï¸ Could not access artifacts for run ${run.id}: ${error.message}`);
              }
            }
          }

          if (!artifactId) {
            throw new Error(`âŒ Could not find artifact '${artifactName}' for commit ${commitSha}`);
          }

          // Download the artifact
          console.log('ğŸ“¥ Downloading artifact...');
          const download = await github.rest.actions.downloadArtifact({
            owner: owner,
            repo: repo,
            artifact_id: artifactId,
            archive_format: 'zip'
          });

          // Save the artifact
          fs.mkdirSync('wheel', { recursive: true });
          fs.writeFileSync('wheel/artifact.zip', Buffer.from(download.data));

          console.log('âœ… Artifact downloaded successfully');

    - name: ğŸ”§ Extract and install DataSON wheel
      run: |
        cd wheel
        unzip -q artifact.zip
        ls -la
        echo "ğŸ“¦ Extracted files:"
        find . -name "*.whl" -type f

        # Install the wheel
        WHEEL_FILE=$(find . -name "*.whl" -type f | head -n1)
        if [ -z "$WHEEL_FILE" ]; then
          echo "âŒ No wheel file found in artifact"
          exit 1
        fi

        echo "ğŸ”§ Installing: $WHEEL_FILE"
        pip install "$WHEEL_FILE"

        # Verify installation
        python -c "import datason; print(f'âœ… DataSON {datason.__version__} installed successfully')"

    - name: ğŸš€ Run benchmarks
      run: |
        mkdir -p data/results docs/results
        
        # Run the appropriate benchmark based on type
        case "${{ github.event.inputs.benchmark_type }}" in
          "pr_optimized")
            echo "ğŸ¯ Running PR-optimized benchmark suite..."
            python scripts/pr_optimized_benchmark.py --output data/results/pr_${{ github.event.inputs.pr_number }}.json
            ;;
          "quick")
            echo "âš¡ Running quick benchmark suite..."
            python scripts/run_benchmarks.py --quick --output data/results/pr_${{ github.event.inputs.pr_number }}.json
            ;;
          "competitive")
            echo "ğŸ Running competitive benchmark suite..."
            python scripts/run_benchmarks.py --competitive --output data/results/pr_${{ github.event.inputs.pr_number }}.json
            ;;
        esac

    - name: ğŸ¨ Generate enhanced report
      run: |
        # Generate Phase 4 enhanced report if available
        if [ -f scripts/phase4_enhanced_reports.py ]; then
          echo "ğŸ¨ Generating Phase 4 enhanced report..."
          python scripts/phase4_enhanced_reports.py \
            --input data/results/pr_${{ github.event.inputs.pr_number }}.json \
            --output docs/results/datason_pr_${{ github.event.inputs.pr_number }}.html \
            --title "DataSON PR #${{ github.event.inputs.pr_number }} Analysis"
        fi

    - name: ğŸ” Regression detection
      run: |
        # Compare against baseline if available
        if [ -f data/results/datason_baseline.json ] && [ -f scripts/regression_detector.py ]; then
          python scripts/regression_detector.py \
            data/results/pr_${{ github.event.inputs.pr_number }}.json \
            --baseline data/results/datason_baseline.json \
            --fail-threshold 0.30 \
            --warn-threshold 0.15 \
            --output regression_analysis.md
          
          echo "REGRESSION_STATUS=$?" >> $GITHUB_ENV
        else
          echo "ğŸ“ No baseline available for regression detection"
          echo "REGRESSION_STATUS=0" >> $GITHUB_ENV
        fi

    - name: ğŸ’¬ Generate PR comment
      run: |
        cat > comment.md << 'EOF'
        # ğŸš€ DataSON PR Performance Analysis
        
        **PR #${{ github.event.inputs.pr_number }}** | **Commit**: `${{ github.event.inputs.commit_sha }}`
        
        ## ğŸ“Š Benchmark Results
        
        Tested against our **Phase 1-4 optimized dataset suite**:
        
        | Test Type | Status | Focus Area |
        |-----------|--------|------------|
        | Web API Response | âœ… | Common serialization patterns |
        | ML Training Data | âœ… | NumPy/Pandas integration |
        | Financial Transaction | âœ… | High-precision decimal handling |
        | Mixed Types Challenge | âœ… | Edge case coverage |
        | Security PII Test | âœ… | PII detection effectiveness |
        
        ## ğŸ“ˆ Performance Analysis
        
        âœ… Benchmarks completed successfully using **${{ github.event.inputs.benchmark_type }}** suite
        - Serialization performance: Analyzed
        - Deserialization efficiency: Measured  
        - Memory usage: Profiled
        - Cross-library compatibility: Verified
        EOF
        
        # Add regression analysis if available
        if [ -f regression_analysis.md ]; then
          echo "" >> comment.md
          echo "## ğŸ” Regression Analysis" >> comment.md
          cat regression_analysis.md >> comment.md
        fi
        
        # Add status summary
        if [ "$REGRESSION_STATUS" = "0" ]; then
          echo "" >> comment.md
          echo "## âœ… Status: Ready for Review" >> comment.md
          echo "No significant performance regressions detected. All benchmarks passed!" >> comment.md
        else
          echo "" >> comment.md
          echo "## âš ï¸ Performance Alert" >> comment.md
          echo "Potential performance regression detected. Please review the analysis above." >> comment.md
        fi
        
        echo "" >> comment.md
        echo "---" >> comment.md
        echo "*Generated by [datason-benchmarks](https://github.com/danielendler/datason-benchmarks) â€¢ Phase 1-4 Testing Suite*" >> comment.md

    - name: ğŸ“ Post comment to DataSON PR
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.BENCHMARK_REPO_TOKEN }}
        script: |
          const fs = require('fs');
          const comment = fs.readFileSync('comment.md', 'utf8');
          const [owner, repo] = '${{ github.event.inputs.datason_repo }}'.split('/');

          await github.rest.issues.createComment({
            issue_number: ${{ github.event.inputs.pr_number }},
            owner, repo, body: comment
          });

    - name: ğŸ“¤ Upload results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ github.event.inputs.pr_number }}
        path: |
          data/results/pr_${{ github.event.inputs.pr_number }}.json
          docs/results/datason_pr_${{ github.event.inputs.pr_number }}.html
          comment.md
          regression_analysis.md
        retention-days: 30

    - name: âŒ Fail on significant regression
      if: env.REGRESSION_STATUS != '0'
      run: |
        echo "âŒ Significant performance regression detected!"
        echo "This workflow will fail to alert the PR author to review performance impact."
        exit 1 