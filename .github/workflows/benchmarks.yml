# This file is generated by tools/gen_workflows.py
# DO NOT EDIT MANUALLY - Edit the Python model instead

name: 📊 Benchmark Validation
on:
  workflow_dispatch:
    inputs:
      benchmark_type:
        description: Type of benchmark to run
        required: false
        default: quick
        type: choice
        options:
          - quick
          - complete
          - comprehensive
  schedule:
    - cron: 0 2 * * *
jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - name: 🔄 Checkout repository
        uses: actions/checkout@v4
      - name: 🐍 Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: pip
      - name: 📦 Install benchmark dependencies
        run: "pip install --upgrade pip\npip install datason orjson ujson msgpack-python jsonpickle\npip install -r requirements.txt"
      - name: 📊 Run benchmarks
        run: "BENCHMARK_TYPE=\"${{ github.event.inputs.benchmark_type || 'quick' }}\"\ntimeout 300 python scripts/run_benchmarks.py --quick --output \"data/results/ci_${BENCHMARK_TYPE}_$(date +%Y%m%d_%H%M%S).json\""
      - name: 💾 Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.run_id }}
          path: data/results/ci_*.json
        if: always()
    timeout-minutes: 30
env:
  PYTHONUNBUFFERED: '1'
