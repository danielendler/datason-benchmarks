
name: ðŸš€ DataSON PR Performance Benchmark

on:
  pull_request:
    branches: [ main ]
    paths:
      - 'src/**'
      - 'datason/**'
      - 'pyproject.toml'
      - 'setup.py'
  workflow_dispatch:
    inputs:
      benchmark_type:
        description: 'Benchmark type to run'
        required: false
        default: 'pr_optimized'
        type: choice
        options:
        - pr_optimized
        - quick
        - competitive

permissions:
  contents: read
  pull-requests: write

jobs:
  build-datason:
    name: ðŸ“¦ Build DataSON Package
    runs-on: ubuntu-latest
    
    outputs:
      artifact-name: ${{ steps.build.outputs.artifact-name }}
      wheel-file: ${{ steps.build.outputs.wheel-file }}
      
    steps:
    - name: ðŸ“¥ Checkout DataSON PR
      uses: actions/checkout@v4
      
    - name: ðŸ Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
        
    - name: ðŸ“¦ Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build wheel setuptools
        
    - name: ðŸ”¨ Build DataSON wheel
      id: build
      run: |
        # Clean any previous builds
        rm -rf dist/ build/ *.egg-info/
        
        # Build wheel
        python -m build --wheel
        
        # Get wheel filename
        WHEEL_FILE=$(ls dist/*.whl | head -n1)
        WHEEL_NAME=$(basename "$WHEEL_FILE")
        
        echo "wheel-file=$WHEEL_NAME" >> $GITHUB_OUTPUT
        echo "artifact-name=datason-pr-${{ github.event.number }}-${{ github.sha }}" >> $GITHUB_OUTPUT
        
        echo "âœ… Built wheel: $WHEEL_NAME"
        ls -la dist/
        
    - name: ðŸ“¤ Upload DataSON wheel
      uses: actions/upload-artifact@v4
      with:
        name: ${{ steps.build.outputs.artifact-name }}
        path: dist/*.whl
        retention-days: 7
        
    - name: ðŸ§ª Quick smoke test
      run: |
        # Install the wheel we just built
        pip install dist/*.whl
        
        # Basic smoke test
        python -c "
        import datason
        print(f'DataSON {datason.__version__} installed successfully')
        
        # Test basic functionality
        test_data = {'test': 'value', 'number': 42}
        serialized = datason.serialize(test_data)
        deserialized = datason.deserialize(serialized)
        assert deserialized == test_data
        print('âœ… Basic serialization test passed')
        "

  benchmark-pr:
    name: ðŸ“Š Run PR Benchmarks
    runs-on: ubuntu-latest
    needs: build-datason
    timeout-minutes: 15
    
    steps:
    - name: ðŸ“¥ Checkout benchmark repository
      uses: actions/checkout@v4
      with:
        repository: ${{ env.BENCHMARK_REPO || 'datason/datason-benchmarks' }}
        path: benchmarks
        
    - name: ðŸ Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
        
    - name: ðŸ’¾ Cache benchmark dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: pr-benchmark-${{ runner.os }}-py3.11-${{ hashFiles('benchmarks/requirements.txt') }}
        restore-keys: |
          pr-benchmark-${{ runner.os }}-py3.11-
          
    - name: ðŸ“¦ Install benchmark dependencies
      run: |
        cd benchmarks
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
        # Install competitor libraries for comparison
        pip install orjson ujson msgpack jsonpickle pandas numpy
        
    - name: ðŸ“¥ Download DataSON PR artifact
      uses: actions/download-artifact@v4
      with:
        name: ${{ needs.build-datason.outputs.artifact-name }}
        path: datason-pr-wheel/
        
    - name: ðŸ”§ Install DataSON from PR
      run: |
        # Install the PR version of DataSON
        pip install datason-pr-wheel/*.whl
        
        # Verify installation
        python -c "
        import datason
        print(f'ðŸ“¦ DataSON {datason.__version__} from PR installed')
        print(f'ðŸ“ Location: {datason.__file__}')
        "
        
    - name: ðŸš€ Run optimized PR benchmark
      run: |
        cd benchmarks
        
        # Create results directory
        mkdir -p data/results docs/results
        
        # Run PR-optimized benchmark suite
        echo "ðŸŽ¯ Running PR-optimized benchmark suite..."
        python scripts/pr_optimized_benchmark.py
        
        # Also run quick competitive for context
        echo "ðŸ“Š Running quick competitive benchmark for context..."
        python scripts/run_benchmarks.py --quick --generate-report
        
      env:
        GITHUB_SHA: ${{ github.sha }}
        GITHUB_REF: ${{ github.ref }}
        GITHUB_RUN_ID: ${{ github.run_id }}
        PR_NUMBER: ${{ github.event.number }}
        
    - name: ðŸ“ˆ Generate Phase 4 enhanced report
      run: |
        cd benchmarks
        
        # Generate Phase 4 enhanced report for PR
        echo "ðŸŽ¨ Generating Phase 4 enhanced PR report..."
        python scripts/phase4_enhanced_reports.py \
          --input data/results/latest_quick.json \
          --output docs/results/pr_${{ github.event.number }}_enhanced.html \
          --title "PR #${{ github.event.number }} Performance Analysis" \
          --pr-mode
          
    - name: ðŸ” Advanced regression detection
      run: |
        cd benchmarks
        
        # Run regression detection against baseline
        echo "ðŸ” Running advanced regression detection..."
        
        if [ -f data/results/baseline.json ]; then
          python scripts/regression_detector.py \
            data/results/latest_quick.json \
            --baseline data/results/baseline.json \
            --pr-comment pr_regression_analysis.md \
            --fail-threshold 0.30 \
            --warn-threshold 0.15 \
            --pr-number ${{ github.event.number }}
          
          REGRESSION_EXIT_CODE=$?
          echo "REGRESSION_DETECTED=$([ $REGRESSION_EXIT_CODE -ne 0 ] && echo 'true' || echo 'false')" >> $GITHUB_ENV
        else
          echo "ðŸ“ No baseline found - this will establish the baseline"
          echo "REGRESSION_DETECTED=false" >> $GITHUB_ENV
          
          cat > pr_regression_analysis.md << 'EOF'
# ðŸ”„ Performance Baseline Establishment

This is the first benchmark run or no previous baseline was found.
Future PRs will be compared against this performance baseline.

## ðŸ“Š Benchmark Results

The benchmark completed successfully and will serve as the baseline for:
- Serialization performance comparisons
- Feature compatibility validation  
- Regression detection in future PRs

EOF
        fi
        
    - name: ðŸ’¬ Generate enhanced PR comment
      run: |
        cd benchmarks
        
        echo "ðŸ“ Generating comprehensive PR comment..."
        
        # Create comprehensive PR comment
        cat > pr_performance_comment.md << 'EOF'
# ðŸš€ PR Performance Analysis

> **Automated Performance Check** for PR #${{ github.event.number }}  
> **Commit**: ${{ github.sha }}  
> **DataSON Version**: Built from this PR

## ðŸ“Š Performance Summary

EOF
        
        # Add regression analysis if available
        if [ -f pr_regression_analysis.md ]; then
          cat pr_regression_analysis.md >> pr_performance_comment.md
          echo "" >> pr_performance_comment.md
        fi
        
        # Add enhanced report link
        cat >> pr_performance_comment.md << 'EOF'
## ðŸ“ˆ Enhanced Interactive Report

A comprehensive Phase 4 enhanced report has been generated with:
- ðŸ“Š Performance tables with smart unit formatting (Î¼s/ms/s)
- ðŸ” ML framework compatibility analysis  
- ðŸ›¡ï¸ Security features effectiveness metrics
- ðŸ’¡ Domain-specific optimization recommendations

**Download the `pr-performance-analysis` artifact** to view the full interactive HTML report.

## ðŸŽ¯ Benchmark Coverage

This PR was tested against our **optimized dataset suite** based on Phase 1-4 learnings:

| Dataset | Domain | Focus Area | Status |
|---------|--------|------------|--------|
| Web API Response | `web_api` | Common serialization patterns | âœ… Tested |
| ML Training Data | `machine_learning` | Complex objects + NumPy | âœ… Tested |
| Financial Transaction | `finance` | Precision decimals/datetime | âœ… Tested |
| Mixed Types Challenge | `type_testing` | Edge case handling | âœ… Tested |
| Security PII Test | `security` | PII detection/redaction | âœ… Tested |

EOF

        # Add performance status
        if [ "$REGRESSION_DETECTED" = "true" ]; then
          cat >> pr_performance_comment.md << 'EOF'
## âš ï¸ Performance Alert

**Potential performance regression detected.** Please review the detailed analysis above.

EOF
        else
          cat >> pr_performance_comment.md << 'EOF'
## âœ… Performance Status

No significant performance regressions detected. This PR maintains or improves performance.

EOF
        fi
        
        cat >> pr_performance_comment.md << 'EOF'
---
*This comment was automatically generated by the DataSON benchmark suite*
EOF
        
    - name: ðŸ’¬ Post PR comment
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          try {
            const comment = fs.readFileSync('benchmarks/pr_performance_comment.md', 'utf8');
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
            
            console.log('âœ… Posted performance analysis comment to PR');
          } catch (error) {
            console.error('âŒ Failed to post PR comment:', error);
          }
          
    - name: ðŸ“¤ Upload comprehensive artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: pr-performance-analysis-${{ github.event.number }}
        path: |
          benchmarks/data/results/pr_optimized_*.json
          benchmarks/data/results/latest_quick.json
          benchmarks/docs/results/pr_${{ github.event.number }}_enhanced.html
          benchmarks/pr_regression_analysis.md
          benchmarks/pr_performance_comment.md
        retention-days: 30
        
    - name: âŒ Fail on critical regression
      if: env.REGRESSION_DETECTED == 'true'
      run: |
        echo "âŒ Critical performance regression detected!"
        echo "This PR introduces performance issues that exceed the acceptable threshold."
        echo "Please review the regression analysis and optimize the changes."
        exit 1
        
    - name: âœ… Performance check complete  
      if: env.REGRESSION_DETECTED != 'true'
      run: |
        echo "âœ… Performance check passed"
        echo "ðŸ“Š No critical regressions detected"
        echo "ðŸš€ This PR is ready for review from a performance perspective"
